<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<!--
This is an example weekly progress report document that team members can use to report their individual progress 
of their ECE477 senior design projects. Weekly progress reports are expected to follow the general guidelines
presented in the "Progress Report Policy" document, posted on Brightspace.  

Please create 4 copies of this example, renaming each copy to <PurdueID>.html, where <PurdueID> corresponds to
the Purdue ITAP Career Account ID given by Purdue to each individual team member. If you have any questions,
contact course staff.
-->
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />

<!--Reconfigurable base tag; used to modify the site root location for root-relative links-->
<!--<base href="https://engineering.purdue.edu/ece477/StudentWebTemplate/" />-->
    <base href="https://engineering.purdue.edu/477grp16/" /> <!-- Replace the N with your team number-->
<!--Content-->
<title>ECE477 Course Documents</title>
<meta name="keywords" content="" />
<meta name="description" content="" />
<meta name="author" content="George Hadley">
<meta name = "format-detection" content = "telephone=no" />
<meta name="viewport" content="width=device-width,initial-scale=1.0">

<!--CSS-->
<link rel="stylesheet" href="css/default.css" type="text/css" media="all" />
<link rel="stylesheet" href="css/responsive.css">
<link rel="stylesheet" href="css/styles.css">
<link rel="stylesheet" href="css/content.css">
<!--[if IE 6]>
<link href="default_ie6.css" rel="stylesheet" type="text/css" />
<![endif]-->

</head>
<body>
<div id="wrapper_site">
    <div id="wrapper_page">
	<!-- Instantiate global site header.-->
	<div id="header"></div>
		<!-- Instantiate site global navigation bar.-->
		<div id="menu"></div>
	
		<!-- Instantiate a page banner image. Page banner images should be 1100x350px and should be located within the local
			img folder located at this directory level. -->
		<div id="banner">
			<img src="Files/img/BannerImgExample.jpg"></img>
		</div>
	
		<!-- Instantiate "tools" needed for a page. Tools are premade functional blocks that can be used to build a page,
			and include things such as a file lister (for listing out homework assignments or tutorials)
		-->
		<div id="content">
            <h2>Progress Report for Joey Collins</h2>
            
            <h4>Week 3:</h4>
            <b>Date:</b> 09/08/2023<br>
            <b>Total Hours:</b> 8<br>
            <b>Cummulative Hours:</b> 24<br>
            <b>Description of Project Design Efforts:</b><br>
            This week, the focus remained on the computer vision software. I worked on fine tuning the tracks to ensure that the puck is the only object being tracked, and it is being tracked with high accuracy. I also began implementing frame by frame predictions on future puck location.
            <br><br>
            <b>Object Detection vs Object Tracking</b><br>
            A large chunk of my time went into changing the methods and parameters of the tracking software. I started by researching object detection vs object tracking.
            At the surface level, it appears that object tracking should be more efficient than object detection. According to <a href="https://learnopencv.com/the-complete-guide-to-object-tracking-in-computer-vision/#:~:text=Usually%20tracking%20algorithms%20are%20faster,and%20speed%20of%20its%20motion."> The Complete Guide to Object Tracking</a>, this is due to the fact that you can use the previous frames of the video to extract information about the location and direction of objects. 
            I agree that this would be true for applications with multiple objects in motion and at relatively low speeds. However, I found that using purely object detection resulted in faster results than object tracking for the air hockey application. 
            I tested this by comparing color based detection to color based detection with a CSRT (Discriminative Correlation Filter with Channel and Spatial Reliability) tracker. With the CRST tracker, I got a playback speed that was slower than the original video speed. This means that the processing was occurring slower than the frames were coming in. In a live video, this would create delays that would not be acceptable for an air hockey application. Shown below is a video of the software that uses the CSRT tracker. <br><br>

            <video autoplay muted loop width="530" height="310"> <source src="Team/progress/colli384_files/CSRT Tracking.mp4" type="video/mp4"> </video><br>
            <i>Puck Tracking with CSRT</i>
            <br><br>

            Due to this discovery, I shifted my focus to completely object detection based methods. I found that because the puck moves so fast and is often occluded by human limbs and goals, tracking would not necessarily be reasonable. We do not care if it is the same puck as before, we just want to find the only moving puck.<br><br>

            <b>Track Tuning</b><br>
            In order to more accurately track the puck, I decided to search through the contours being created by the color mask, and choose the one with the largest area to be highlighted. This would filter out any miscellaneous bounding boxes for things like mallets. 
            I have spoken with the team about acquiring green pucks with low potential for glare for the purposes of color filtering. I found that any varying light reflecting off of the puck can have a significant impact on the perceived color. As a result, we will be looking for matte pucks for the final design. Having one track being followed at all times also allows for ease of coordinate determination. Shown below is a video of the speed at which purely color filtering can be done on a pre-recorded video.<br><br>

            <video autoplay muted loop width="530" height="310"> <source src="Team\progress\colli384_files\Color Tracking.mp4" type="video/mp4"> </video><br>
            <i>Puck Tracking with Color Filtering</i>
            <br><br>

            <b>Frame by Frame Coordinate Prediction</b><br>
            I began working on the framework for what will be the future puck location algorithm. To start off, I used the moments created by the single largest contour to find the centroid of the object. 
            Ideally, this would be the center of the puck every time. Occasionally, the largest contour will be one of the mallets, but that should not be a problem once we switch to a green puck. With this centroid, 
            I was able to use the numpy image pixel array as my coordinate system and locate the puck at any given frame. To determine the "velocity" of the puck, which in this case is just the distance and direction per frame, I kept a history of the previous frame's centroid. 
            I found the difference between new location and old location, and used that value to predict where the puck will be in the next frame. Obviously, this falls apart once the puck collides with a wall. This is a problem that I plan to address next week. To test this algorithm, 
            I printed out the velocity vector of the puck, the predicted location for the next frame, and the actual location in the next frame. Shown below is a video of this process.<br><br>

            <video autoplay muted loop width="550" height="310"> <source src="Team\progress\colli384_files\Location Prediction.mp4" type="video/mp4"> </video><br>
            <i>Frame by Frame Puck Location Prediction</i>
            <br><br>

            As far as results go, I am fairly happy with the progress that I have made with the detections and basic trajectory prediction. I think that these steps will serve as a good foundation for what the project will become. I learned that using CSRT may not be the correct course of action for our purposes and that it is much quicker to just look for a certain color in a frame. 
            Looking forward, I want to start developing a more advanced algorithm for future puck location predictions that take into account the possibility of wall collisions. We also received our camera this week, so I would like to start working with live video as soon as possible. <br><br>
    

            <h4>Weeks 1-2:</h4>
            <b>Date:</b> 09/01/2023<br>
            <b>Total Hours:</b> 16<br>
            <b>Cummulative Hours:</b> 16<br>
            <b>Description of Project Design efforts:</b><br>
            I dedicated the first two weeks of my time to my research goals. As the software engineer for this team, I decided that a solid majority of my time would be best spent learning the basics of computer vision to create a strong foundation for our hockey puck tracking software. The rest of my time was spent with miscellaneous endeavors.
            <br><br>
            <b>Computer Vision Research</b><br>
            As stated previously, the majority of my time went into learning the basics of computer vision, as I have not had any experience with the topic. Abby and I will be doing most of the work on the detection and tracking software, so we decided to begin prototyping using the OpenCV library in Python.
            I started off by watching 2 tutorials on object detection and tracking. The first is called <a href="https://youtu.be/O3b8lVF93jU?si=zo2YENBCpAHVSnqZ"> Object Tracking with Opencv and Python</a>. The second is called <a href="https://youtu.be/GgGro5IV-cs?si=gAnJfifMMWW31Tew"> Object Tracking from scratch with OpenCV and Python</a>. Both were made by a channel called Pysource.
            These two videos provided good information to begin writing my own versions of object detection. I first began by creating a sample video using the videotestsrc element of gstreamer. It was meant to replicate a puck bouncing back and forth around a table. The code I wrote to detect the puck filtered out stagnant objects, and followed dynamic objects using a technique that creates a "mask". Below is a screenshot of this tracking. <br><br>

            <img src="Team/progress/colli384_files/figure1.png" alt="Object Detection with Oversimplified Video" width="390" height="338"> <br>
            <i>Object Detection with Oversimplified Video</i> <br><br>
            
            The next step I took was trying to do object detection on a real-world example. Abby shared the video of two people playing <a href="https://youtu.be/e_cz4DaimyM?si=zmTch2UO63U3RgJN"> mini air hockey</a>, which was quite helpful for a test example.
            The code that I used for the gstreamer example did a horrible job of tracking the puck because it was poorly written and could not handle multiple moving objects at one time. In order to fix this, I had to change the thresholds for a moving object to be classified as an object of interest.
            The contours on the mask each hold an area value that indicates how many pixels the contour takes up on the screen. I increased the lower limit for the area to classify an object as important. Originally, I had it at 100 pixels, but I increased it to anything between 3000 and 5000 pixels, which did a fairly nice job of filtering out any miscellaneous movement, such as hands. Below is an image demonstrating the accuracy of the previously mentioned method. <br><br>

            <img src="Team/progress/colli384_files/figure2.png" alt="Imperfect Object Detection with Real Video" width="529" height="309"> <br>
            <i>Imperfect Object Detection with Real Video</i> <br><br>

            Because motion alone was not enough to distinguish the puck from other objects, I decided to filter out objects by color. To do this, I had to figure out what the hsv range of the puck was. I was not familiar with hsv previously, so I had to look into that. It is similar to an rgb color scheme, but hsv stands for hue, saturation, and value. Once I found the color of the puck through some experimentation, I filtered out any colors that did not fit in that range. I combined the color mask and the motion mask using a bitwise and so that the only things left in the video were moving objects in that color spectrum.
            This technique turned out to be very successful relative to previous attempts. An image of this technique is shown below. <br><br>

            <img src="Team/progress/colli384_files/figure3.png" alt="Object Detection with Motion and Color Mask" width="529" height="309"> <br>
            <i>Object Detection with Motion and Color Mask</i> <br><br>
            
            Abby has been working on shape-based filtering, which could work well with color filtering. I believe that if we choose a puck color that is drastically different from the table and paddles, it would be quite simple to locate the puck. It may turn out in the future that we have to remove the motion mask because of the case where the puck sits still in the middle of the table. The software would not detect an object because it would not be moving. The next step in my research will be keeping track of a specific object, which in this case will be the puck.
            Once we obtain our air hockey table and camera, I would also like to start doing some testing using a live video feed, as opposed to pre-recorded video.
            I think I made good progress on learning OpenCV basics during weeks 1 and 2, and think that I am where I should be with respect to the completion of PSDR 5.
            <br><br>


            <br>    
        </div>
	
		<!-- Instantiate global footer. Any changes to the footer should be made through the top-level file "footer.html" -->
		<div id="footer"></div>
    </div>
</div>

<!--JS-->
<script src="js/jquery.js"></script>
<script src="js/jquery-migrate-1.1.1.js"></script>

<script type="text/javascript">
$(document).ready(function() {
    $("#header").load("header.html");
	$("#menu").load("navbar.html");
	$("#footer").load("footer.html");
});
</script>
</body>
</html>
